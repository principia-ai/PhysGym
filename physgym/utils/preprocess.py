import json
import os
import re
import sys
from tqdm import tqdm
from physgym.utils.llm_providers import generate_with_provider, load_api_key

def load_json_file(file_path):
    """
    Load JSON data from a file.
    
    Args:
        file_path (str): Path to the JSON file
        
    Returns:
        list: List of problem items from the JSON file
    """
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        return data
    except Exception as e:
        print(f"Error loading JSON file {file_path}: {e}")
        sys.exit(1)

def load_prompt_template(file_path):
    """
    Load the prompt template from a file.
    
    Args:
        file_path (str): Path to the prompt template file
        
    Returns:
        str: The prompt template
    """
    try:
        with open(file_path, 'r') as f:
            prompt_template = f.read()
        return prompt_template
    except Exception as e:
        print(f"Error loading prompt template from {file_path}: {e}")
        sys.exit(1)

def create_prompt_for_problem(prompt_template, problem):
    """
    Create a prompt for a specific problem.
    
    Args:
        prompt_template (str): The prompt template
        problem (dict): Problem data including content and answer
        
    Returns:
        str: The formatted prompt
    """
    # Extract relevant content from the problem
    problem_content = {
        "content": problem.get("content", ""),
        "answer": problem.get("answer", "")
    }
    
    # Format the prompt by replacing {problem} with the JSON string
    formatted_prompt = prompt_template.replace("{problem}", json.dumps(problem_content))
    
    return formatted_prompt

def extract_sections(generated_text):
    """
    Extract Python code and variable descriptions from the generated text.
    
    Args:
        generated_text (str): The text generated by the LLM
        
    Returns:
        dict: Dictionary containing the extracted sections
    """
    # Initialize result dictionary
    sections = {
        "python_code": "",
        "equation": "",
        "input_variables": {},
        "output_variable": {},
        "dummy_variables": {}  # Default is empty dict if no dummy variables
    }
    
    # Extract Python code
    python_match = re.search(r'<python>(.*?)</python>', generated_text, re.DOTALL)
    if python_match:
        sections["python_code"] = python_match.group(1).strip()
    
    # Extract JSON data
    json_match = re.search(r'```json\s*(.*?)\s*```', generated_text, re.DOTALL)
    if json_match:
        try:
            json_data = json.loads(json_match.group(1))
            # Extract elements from the JSON data
            sections["equation"] = json_data.get("equation", "")
            sections["input_variables"] = json_data.get("input variables", {})
            sections["output_variable"] = json_data.get("output variable", {})
            sections["dummy_variables"] = json_data.get("dummy variable", {})
        except json.JSONDecodeError as e:
            print(f"Error parsing JSON from generated text: {e}")
    
    return sections


def process_samples(samples_file, prompt_file, output_file="processed_samples.json", env_file="api_keys.env"):
    """
    Process all samples using the prompt and save results to a JSON file.
    
    Args:
        samples_file (str): Path to the samples JSON file
        prompt_file (str): Path to the prompt template file
        output_file (str): Path to the output JSON file
        env_file (str): Path to the environment file containing API key
    """
    # Load samples and prompt template
    samples = load_json_file(samples_file)
    prompt_template = load_prompt_template(prompt_file)
    
    # Load API key from .env file
    openrouter_api_key = load_api_key(env_file)
    if not openrouter_api_key:
        print("Error: OpenRouter API key not found. Please add OPENROUTER_API_KEY to your api_keys.env file.")
        sys.exit(1)
    else:
        print("Successfully loaded OpenRouter API key.")
    
    # Create a list to store processed results
    processed_samples = []
    
    # Process each sample
    for sample in tqdm(samples, desc="Processing samples"):
        problem_id = sample.get("id")
        
        # Create a deep copy of the sample to avoid modifying the original
        processed_sample = {**sample}
        
        # Create prompt for this problem
        prompt = create_prompt_for_problem(prompt_template, sample)
        
        # Generate content using LLM provider
        generated_content, _ = generate_with_provider(
            prompt=prompt,
            model="anthropic/claude-3.7-sonnet",
            provider="openrouter",
            api_key=openrouter_api_key,
            system_message="You are an expert at understanding and reformatting physics problems."
        )
        
        # Extract sections from generated content
        sections = extract_sections(generated_content)
        
        # Add the extracted sections to the processed sample
        processed_sample["python_code"] = sections["python_code"]
        processed_sample["equation"] = sections["equation"]
        processed_sample["input_variables"] = sections["input_variables"]
        processed_sample["output_variable"] = sections["output_variable"]
        processed_sample["dummy_variables"] = sections["dummy_variables"]
        
        # Also save the original generated content for reference
        processed_sample["generated_content"] = generated_content
        
        # Add to the list of processed samples
        processed_samples.append(processed_sample)
    
    # Save all processed samples to a JSON file
    try:
        with open(output_file, 'w') as f:
            json.dump(processed_samples, f, indent=2)
        print(f"Successfully saved all processed samples to {output_file}")
    except Exception as e:
        print(f"Error saving processed samples to {output_file}: {e}")
    
    print(f"Finished processing {len(samples)} samples.")

def save_python_file(problem_id, sections, output_dir="samples"):
    """
    Save the processed data to a Python file.
    
    Args:
        problem_id (int): The ID of the problem
        sections (dict): Extracted sections (code and descriptions)
        output_dir (str): Directory to save the Python files
    """
    os.makedirs(output_dir, exist_ok=True)
    
    output_path = os.path.join(output_dir, f"{problem_id}.py")
    
    # Create the output content with necessary comments
    output_content = f"{sections['python_code']}\n\n"
    output_content += "# Variable descriptions:\n"
    output_content += "# \n"
    output_content += "# Equation:\n"
    output_content += f"# {sections['equation']}\n"
    output_content += "#\n"
    output_content += "# Input Variables:\n"
    for var, desc in sections['input_variables'].items():
        output_content += f"# {var}: {desc}\n"
    output_content += "#\n"
    output_content += "# Output Variable:\n"
    for var, desc in sections['output_variable'].items():
        output_content += f"# {var}: {desc}\n"
    output_content += "#\n"
    
    # Only add dummy variables section if there are any
    if sections['dummy_variables']:
        output_content += "# Dummy Variables (not used in calculation):\n"
        for var, desc in sections['dummy_variables'].items():
            output_content += f"# {var}: {desc}\n"
    
    try:
        with open(output_path, 'w') as f:
            f.write(output_content)
    except Exception as e:
        print(f"Error saving Python file to {output_path}: {e}")

if __name__ == "__main__":
    # Define file paths
    from pathlib import Path
    package_dir = Path(__file__).parent.parent
    samples_file = ".temp/full_items.json"
    prompt_file = package_dir / "prompts" / "preprocess.txt"
    output_file = "full_samples.json"
    env_file = "api_keys.env"
    
    # Process the samples
    process_samples(samples_file, str(prompt_file), output_file, env_file)
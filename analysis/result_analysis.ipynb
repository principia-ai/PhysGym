{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis\n",
    "\n",
    "This notebook loads and analyzes the models_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models Data\n",
    "\n",
    "First, we'll find all the models_data.json files and load them into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all models_data.json files\n",
    "data_files = glob.glob('histories/baseline/**/models_data.json', recursive=True)\n",
    "print(f\"Found {len(data_files)} model data files\")\n",
    "\n",
    "# If no files found, maybe we need to run the postprocessing script first\n",
    "if len(data_files) == 0:\n",
    "    print(\"No models_data.json files found. You may need to run postprocess_experiments.py first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from a models_data.json file\n",
    "def load_models_data(file_path):\n",
    "    # Extract experiment configuration from the path\n",
    "    config = os.path.dirname(file_path).replace('histories/baseline/', '')\n",
    "    mode, model = config.split('/')\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Convert nested structure to DataFrame rows\n",
    "        rows = []\n",
    "        for _, experiments in data.items():\n",
    "            for exp in experiments:\n",
    "                exp_copy = exp.copy()\n",
    "                exp_copy['model'] = model\n",
    "                exp_copy['config'] = mode\n",
    "                # Handle unique_hypotheses (convert lists back to sets for counting if needed)\n",
    "                if 'unique_hypotheses' in exp_copy and isinstance(exp_copy['unique_hypotheses'], list):\n",
    "                    exp_copy['num_unique_hypotheses'] = len(exp_copy['unique_hypotheses'])\n",
    "                rows.append(exp_copy)\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load all data files into a single DataFrame\n",
    "df = [load_models_data(file) for file in data_files]\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "# Display basic information\n",
    "if not df.empty:\n",
    "    print(f\"Loaded {len(df)} experiment records across {df['model'].nunique()} models\")\n",
    "    print(f\"Configurations: {df['config'].unique()}\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_configs = sorted(df['config'].unique())\n",
    "mapping = {\n",
    "        \"default\": \"Level 1\",\n",
    "        \"no_context\": \"Level 2\",\n",
    "        \"no_description\": \"Level 3\",\n",
    "        \"no_description_anonymous\": \"Level 4\"\n",
    "    }\n",
    "df['config'] = df['config'].map(mapping)\n",
    "\n",
    "mapping = {\n",
    "        \"openai_o4-mini-high\": \"OpenAI o4 Mini\",\n",
    "        \"google_gemini-2.5-flash-preview:thinking\": \"Gemini 2.5 Flash\",\n",
    "        \"claude-3-7-sonnet-20250219\": \"Claude 3.7 Sonnet\",\n",
    "        \"google_gemini-2.5-pro-preview\": \"Gemini 2.5 Pro\",\n",
    "        \"vllm_Qwen3-32B\": \"Qwen3-32B\",\n",
    "        \"ollama_gpt-oss_20b\": \"gpt-oss-20B\"\n",
    "    }\n",
    "df['model'] = df['model'].map(mapping)\n",
    "df['id'] = df['id'].astype(int)\n",
    "df['id'] = df['id'].astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with missing ids\n",
    "missing_ids = df[df['id'].isna()]\n",
    "if not missing_ids.empty:\n",
    "    print(f\"Found {len(missing_ids)} rows with missing ids\")\n",
    "    print(missing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_runs = df[df['success'] == True]\n",
    "\n",
    "# 2. Group by 'model' and 'config' and aggregate the specified columns.\n",
    "#    We'll sum the counts for each group.\n",
    "#    Using 'num_unique_hypotheses' as it is a numeric representation.\n",
    "result = successful_runs.groupby(['model', 'config']).agg(\n",
    "    avg_samples_used=('samples_used', 'mean'),\n",
    "    avg_test_used=('test_used', 'mean'),\n",
    "    avg_iterations=('iterations', 'mean'),\n",
    "    avg_num_unique_hypotheses=('num_unique_hypotheses', 'mean'),  # Summing the numeric count\n",
    "    avg_hypotheses_count=('hypotheses_count', 'mean')\n",
    ").reset_index()\n",
    "result = result.round(2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate = df.groupby(['model', 'config'])['success'].mean().reset_index()\n",
    "success_rate = success_rate.rename(columns={'success': 'Acc_rate'})\n",
    "success_rate['Acc_rate'] = (success_rate['Acc_rate'] * 100).round(2)\n",
    "print(success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummy = df[df['num_dummy_var'] > 0]\n",
    "success_rate = df_with_dummy.groupby(['model', 'config'])['success'].mean().reset_index()\n",
    "success_rate = success_rate.rename(columns={'success': 'Acc_rate'})\n",
    "success_rate['Acc_rate'] = (success_rate['Acc_rate'] * 100).round(2)\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solved Sets of a Model Under Given Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"Level 1\"\n",
    "df_L1 = df[df['config'] == level]\n",
    "Qwen_L1 = df_L1[df_L1['model'] == 'Qwen3-32B']\n",
    "Qwen_L1_success = Qwen_L1[Qwen_L1['success'] == True]\n",
    "Qwen_L1_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solved sets problems of 3 model under a given level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any problem that is solved by some models but not others?\n",
    "# Transform ID into categorical values\n",
    "level = \"Level 1\"\n",
    "\n",
    "df_L1 = df[df['config'] == level]\n",
    "# Create a pivot table with problem IDs as index, models as columns, and success as values\n",
    "problem_solution_matrix = df_L1.pivot_table(\n",
    "    index='id',\n",
    "    columns='model',\n",
    "    values='success',\n",
    "    observed='False',\n",
    "    aggfunc='any'  # Use 'any' to check if any attempt was successful\n",
    ").fillna(False)  # Fill NaN values with False (unsolved)\n",
    "\n",
    "# Display the matrix\n",
    "# print(problem_solution_matrix)\n",
    "# Find problems solved by Claude but not by others\n",
    "claude_solved = problem_solution_matrix['Claude 3.7 Sonnet'] == True\n",
    "others_unsolved = (problem_solution_matrix['OpenAI o4 Mini'] == False) | (problem_solution_matrix['Gemini 2.5 Flash'] == False)\n",
    "claude_only_solved = problem_solution_matrix[claude_solved & others_unsolved]\n",
    "\n",
    "# print(f\"Problems solved by Claude but not by others at {level}\")\n",
    "# print(claude_only_solved)\n",
    "\n",
    "# Get the statistics we need to draw a Venn Diagram for the 3 sets of solved problems with the 3 models.\n",
    "# Get the sets of solved problems for each model\n",
    "claude_solved = set(problem_solution_matrix[problem_solution_matrix['Claude 3.7 Sonnet']].index)\n",
    "openai_solved = set(problem_solution_matrix[problem_solution_matrix['OpenAI o4 Mini']].index)\n",
    "gemini_solved = set(problem_solution_matrix[problem_solution_matrix['Gemini 2.5 Flash']].index)\n",
    "\n",
    "# Calculate intersection and union statistics\n",
    "claude_only = claude_solved - (openai_solved | gemini_solved)\n",
    "openai_only = openai_solved - (claude_solved | gemini_solved)\n",
    "gemini_only = gemini_solved - (claude_solved | openai_solved)\n",
    "\n",
    "claude_openai = claude_solved & openai_solved - gemini_solved\n",
    "claude_gemini = claude_solved & gemini_solved - openai_solved\n",
    "openai_gemini = openai_solved & gemini_solved - claude_solved\n",
    "\n",
    "all_solved = claude_solved & openai_solved & gemini_solved\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nVenn Diagram Statistics for {level}:\")\n",
    "print(f\"Total problems: {len(problem_solution_matrix)}\")\n",
    "print(f\"\\nClaude solved: {len(claude_solved)}\")\n",
    "print(f\"OpenAI solved: {len(openai_solved)}\")\n",
    "print(f\"Gemini solved: {len(gemini_solved)}\")\n",
    "\n",
    "print(\"\\nUnique problems solved by each model:\")\n",
    "print(f\"\\nClaude only: {len(claude_only)} Problems, IDs: {claude_only}\")\n",
    "print(f\"OpenAI only: {len(openai_only)} Problems, IDs: {openai_only}\")\n",
    "print(f\"Gemini only: {len(gemini_only)} Problems, IDs: {gemini_only}\")\n",
    "\n",
    "print(\"\\nProblems solved by only 2 of them:\")\n",
    "print(f\"\\nClaude + OpenAI: {len(claude_openai)} Problems, IDs: {claude_openai}\")\n",
    "print(f\"Claude + Gemini: {len(claude_gemini)} Problems, IDs: {claude_gemini}\")\n",
    "print(f\"OpenAI + Gemini: {len(openai_gemini)} Problems, IDs: {openai_gemini}\")\n",
    "\n",
    "print(f\"\\n Problems solved by all three models: {len(all_solved)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_problems = set(problem_solution_matrix.index)\n",
    "gemini_unsolved = all_problems - gemini_solved\n",
    "np.array(gemini_unsolved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Venn Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_circles\n",
    "# Create the Venn diagram\n",
    "plt.figure(figsize=(6, 5), dpi=300)\n",
    "diagram = venn3(subsets=(len(claude_only), len(openai_only), len(claude_openai), \n",
    "                         len(gemini_only), len(claude_gemini), len(openai_gemini), \n",
    "                         len(all_solved)),\n",
    "               set_labels=('Claude 3.7 Sonnet', 'OpenAI o4 Mini', 'Gemini 2.5 Flash'))\n",
    "\n",
    "# Set colors for each model\n",
    "if diagram.patches:\n",
    "    # Claude (A) - A color related to Anthropic/Claude - light purple\n",
    "    diagram.get_patch_by_id('100').set_color(\"#CCAE91\")  \n",
    "    \n",
    "    # OpenAI (B) - OpenAI brand color - light teal\n",
    "    diagram.get_patch_by_id('010').set_color(\"#9AB39C\")  \n",
    "    \n",
    "    # Gemini (C) - Google/Gemini brand color - light blue\n",
    "    diagram.get_patch_by_id('001').set_color(\"#C3B8E4\") \n",
    "\n",
    "# Add circles for better visibility\n",
    "venn3_circles(subsets=(len(claude_only), len(openai_only), len(claude_openai), \n",
    "                         len(gemini_only), len(claude_gemini), len(openai_gemini), \n",
    "                         len(all_solved)), \n",
    "             linestyle='dashed', linewidth=1, color='gray')\n",
    "\n",
    "# Calculate total problems solved by each model for the title\n",
    "total_claude = len(claude_solved)\n",
    "total_openai = len(openai_solved)\n",
    "total_gemini = len(gemini_solved)\n",
    "total_problems = len(problem_solution_matrix)\n",
    "\n",
    "# Add title and subtitle with statistics\n",
    "plt.title(f'{level} Solved Problems\\n', fontsize=16)\n",
    "# plt.figtext(0.5, 0.01, \n",
    "#            f'Total Problems: {total_problems} | ' +\n",
    "#            f'Claude: {total_claude} ({total_claude/total_problems:.1%}) | ' +\n",
    "#            f'OpenAI: {total_openai} ({total_openai/total_problems:.1%}) | ' +\n",
    "#            f'Gemini: {total_gemini} ({total_gemini/total_problems:.1%})',\n",
    "#            ha='center', fontsize=12)\n",
    "\n",
    "# Add the counts to each section of the diagram\n",
    "for idx, subset in enumerate(('100', '010', '110', '001', '101', '011', '111')):\n",
    "    if diagram.get_label_by_id(subset):\n",
    "        diagram.get_label_by_id(subset).set_text(f'{diagram.get_label_by_id(subset).get_text()}')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "# plt.savefig('ai_model_comparison_venn.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solved sets of one model under different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = \"Gemini 2.5 Flash\" # “Claude 3.7 Sonnet” or “OpenAI o4 Mini” or “Gemini 2.5 Flash”\n",
    "\n",
    "df_model = df[df['model'] == Model]\n",
    "# Create a pivot table with problem IDs as index, models as columns, and success as values\n",
    "problem_solution_matrix = df_model.pivot_table(\n",
    "    index='id',\n",
    "    columns='config',\n",
    "    values='success',\n",
    "    observed='False',\n",
    "    aggfunc='any'  # Use 'any' to check if any attempt was successful\n",
    ").fillna(False)  # Fill NaN values with False (unsolved)\n",
    "\n",
    "# Get the statistics we need to draw a Venn Diagram for the 4 sets of solved problems under 4 levels.\n",
    "# Get the sets of solved problems for each level\n",
    "level1_solved = set(problem_solution_matrix[problem_solution_matrix['Level 1'] == True].index)\n",
    "level2_solved = set(problem_solution_matrix[problem_solution_matrix['Level 2'] == True].index)\n",
    "level3_solved = set(problem_solution_matrix[problem_solution_matrix['Level 3'] == True].index)\n",
    "level4_solved = set(problem_solution_matrix[problem_solution_matrix['Level 4'] == True].index)\n",
    "\n",
    "# Calculate intersections for Venn diagram\n",
    "level1_only = level1_solved - level2_solved - level3_solved - level4_solved\n",
    "level2_only = level2_solved - level1_solved - level3_solved - level4_solved\n",
    "level3_only = level3_solved - level1_solved - level2_solved - level4_solved\n",
    "level4_only = level4_solved - level1_solved - level2_solved - level3_solved\n",
    "\n",
    "level1_2 = (level1_solved & level2_solved) - level3_solved - level4_solved\n",
    "level1_3 = (level1_solved & level3_solved) - level2_solved - level4_solved\n",
    "level1_4 = (level1_solved & level4_solved) - level2_solved - level3_solved\n",
    "level2_3 = (level2_solved & level3_solved) - level1_solved - level4_solved\n",
    "level2_4 = (level2_solved & level4_solved) - level1_solved - level3_solved\n",
    "level3_4 = (level3_solved & level4_solved) - level1_solved - level2_solved\n",
    "\n",
    "level1_2_3 = (level1_solved & level2_solved & level3_solved) - level4_solved\n",
    "level1_2_4 = (level1_solved & level2_solved & level4_solved) - level3_solved\n",
    "level1_3_4 = (level1_solved & level3_solved & level4_solved) - level2_solved\n",
    "level2_3_4 = (level2_solved & level3_solved & level4_solved) - level1_solved\n",
    "\n",
    "all_levels = level1_solved & level2_solved & level3_solved & level4_solved\n",
    "\n",
    "# Print the results\n",
    "print(f\"Level 1 only: {len(level1_only)} problems\")\n",
    "print(f\"Level 2 only: {len(level2_only)} problems\")\n",
    "print(f\"Level 3 only: {len(level3_only)} problems\")\n",
    "print(f\"Level 4 only: {len(level4_only)} problems\")\n",
    "print(f\"Level 1 & 2 only: {len(level1_2)} problems\")\n",
    "print(f\"Level 1 & 3 only: {len(level1_3)} problems\")\n",
    "print(f\"Level 1 & 4 only: {len(level1_4)} problems\")\n",
    "print(f\"Level 2 & 3 only: {len(level2_3)} problems\")\n",
    "print(f\"Level 2 & 4 only: {len(level2_4)} problems\")\n",
    "print(f\"Level 3 & 4 only: {len(level3_4)} problems\")\n",
    "print(f\"Level 1, 2 & 3 only: {len(level1_2_3)} problems\")\n",
    "print(f\"Level 1, 2 & 4 only: {len(level1_2_4)} problems\")\n",
    "print(f\"Level 1, 3 & 4 only: {len(level1_3_4)} problems\")\n",
    "print(f\"Level 2, 3 & 4 only: {len(level2_3_4)} problems\")\n",
    "print(f\"All levels: {len(all_levels)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level4_unsolved = all_problems - level4_solved\n",
    "print(np.array(level4_unsolved))\n",
    "print(len(level4_unsolved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Venn Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define level names\n",
    "level_names = ['Level 1', 'Level 2', 'Level 3', 'Level 4']\n",
    "# Create a dictionary to count combinations\n",
    "combinations_count = {}\n",
    "\n",
    "# Assuming we have the same region variables as your Venn diagram code\n",
    "# Binary codes: 1000=Level1 only, 0100=Level2 only, etc.\n",
    "combinations_count['1000'] = len(level1_only)\n",
    "combinations_count['0100'] = len(level2_only)\n",
    "combinations_count['1100'] = len(level1_2)\n",
    "combinations_count['0010'] = len(level3_only)\n",
    "combinations_count['1010'] = len(level1_3)\n",
    "combinations_count['0110'] = len(level2_3)\n",
    "combinations_count['1110'] = len(level1_2_3)\n",
    "combinations_count['0001'] = len(level4_only)\n",
    "combinations_count['1001'] = len(level1_4)\n",
    "combinations_count['0101'] = len(level2_4)\n",
    "combinations_count['1101'] = len(level1_2_4)\n",
    "combinations_count['0011'] = len(level3_4)\n",
    "combinations_count['1011'] = len(level1_3_4)\n",
    "combinations_count['0111'] = len(level2_3_4)\n",
    "combinations_count['1111'] = len(all_levels)\n",
    "\n",
    "index_tuples = []\n",
    "counts_for_multiindex_series = []\n",
    "\n",
    "ordered_set_names = level_names\n",
    "\n",
    "for binary_representation, count in combinations_count.items():\n",
    "    boolean_tuple = tuple(bit == '1' for bit in binary_representation)\n",
    "    index_tuples.append(boolean_tuple)\n",
    "    counts_for_multiindex_series.append(count)\n",
    "\n",
    "upset_data_multiindex = pd.Series(dtype=int)\n",
    "multi_idx = pd.MultiIndex.from_tuples(index_tuples, names=ordered_set_names)\n",
    "upset_data_multiindex = pd.Series(counts_for_multiindex_series, index=multi_idx, dtype=int)\n",
    "print(\"Successfully created Series with MultiIndex:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import plot\n",
    "# Calculate total per level for the subtitle\n",
    "total_level1 = len(level1_solved)\n",
    "total_level2 = len(level2_solved)\n",
    "total_level3 = len(level3_solved)\n",
    "total_level4 = len(level4_solved)\n",
    "total_problems = len(problem_solution_matrix)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), dpi=300)\n",
    "plot(upset_data_multiindex,\n",
    "        sort_by='degree',\n",
    "        facecolor=\"#607D8B\",\n",
    "        show_counts=True,\n",
    "        fig=fig)\n",
    "\n",
    "plt.suptitle(f'Solved Sets by {Model} Under Different Level', fontsize=16, y=0.98)\n",
    "if total_problems > 0:\n",
    "    stats_text = (f'Total Problems: {total_problems} | '\n",
    "                    f'L1: {total_level1} ({total_level1/total_problems:.1%}) | '\n",
    "                    f'L2: {total_level2} ({total_level2/total_problems:.1%}) | '\n",
    "                    f'L3: {total_level3} ({total_level3/total_problems:.1%}) | '\n",
    "                    f'L4: {total_level4} ({total_level4/total_problems:.1%})')\n",
    "else:\n",
    "    stats_text = \"Statistics unavailable\"\n",
    "fig.text(0.5, 0.02, stats_text, ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# patches = [mpatches.Patch(color=color, label=level) for level, color in level_colors.items()]\n",
    "# fig.legend(handles=patches, loc='upper right', bbox_to_anchor=(0.99, 0.95), title=\"Levels\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.93])\n",
    "# plt.savefig('difficulty_level_upset_multiindex.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Plotting with MultiIndex Series attempted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
